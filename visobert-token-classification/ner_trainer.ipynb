{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dataset import read_ner_file\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np \n",
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "from transformers import AdamW\n",
    "from tqdm import tqdm \n",
    "import torcheval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "LABEL_2_ID = {'B-PATIENT_ID': 0, \n",
    "    'I-PATIENT_ID': 1, \n",
    "    'B-NAME': 2, \n",
    "    'I-NAME': 3, \n",
    "    'B-AGE': 4, \n",
    "    'I-AGE': 5, \n",
    "    'B-GENDER': 6, \n",
    "    'I-GENDER': 7, \n",
    "    'B-JOB': 8, \n",
    "    'I-JOB': 9, \n",
    "    'B-LOCATION': 10, \n",
    "    'I-LOCATION': 11, \n",
    "    'B-ORGANIZATION': 12, \n",
    "    'I-ORGANIZATION': 13, \n",
    "    'B-SYMPTOM_AND_DISEASE': 14, \n",
    "    'I-SYMPTOM_AND_DISEASE': 15, \n",
    "    'B-TRANSPORTATION': 16, \n",
    "    'I-TRANSPORTATION': 17, \n",
    "    'B-DATE': 18, \n",
    "    'I-DATE': 19, \n",
    "    'O': 20\n",
    "}\n",
    "\n",
    "ID_2_LABEL = {0: 'B-PATIENT_ID', \n",
    "    1: 'I-PATIENT_ID', \n",
    "    2: 'B-NAME', \n",
    "    3: 'I-NAME', \n",
    "    4: 'B-AGE', \n",
    "    5: 'I-AGE', \n",
    "    6: 'B-GENDER', \n",
    "    7: 'I-GENDER', \n",
    "    8: 'B-JOB', \n",
    "    9: 'I-JOB', \n",
    "    10: 'B-LOCATION', \n",
    "    11: 'I-LOCATION', \n",
    "    12: 'B-ORGANIZATION', \n",
    "    13: 'I-ORGANIZATION', \n",
    "    14: 'B-SYMPTOM_AND_DISEASE', \n",
    "    15: 'I-SYMPTOM_AND_DISEASE', \n",
    "    16: 'B-TRANSPORTATION', \n",
    "    17: 'I-TRANSPORTATION', \n",
    "    18: 'B-DATE', \n",
    "    19: 'I-DATE', \n",
    "    20: 'O'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_ner_file(\"./data/syllable/train_syllable.conll\")\n",
    "df_test = read_ner_file(\"./data/syllable/test_syllable.conll\")\n",
    "\n",
    "df_train = pd.DataFrame(data=df_train)\n",
    "df_train = df_train.convert_dtypes()\n",
    "\n",
    "df_test = pd.DataFrame(data=df_test) \n",
    "df_test = df_test.convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converter(tokens): \n",
    "    converted_tokens = [] \n",
    "\n",
    "    for token in tokens: \n",
    "        converted_tokens.append(LABEL_2_ID[token])\n",
    "\n",
    "    return converted_tokens\n",
    "\n",
    "df_train[\"tokens\"] = df_train[\"tokens\"].apply(func=converter)\n",
    "df_test[\"tokens\"] = df_test[\"tokens\"].apply(func=converter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"uitnlp/visobert\")\n",
    "model.lm_head.decoder = nn.Linear(in_features=768, out_features=len(ID_2_LABEL), bias=True)\n",
    "model = model.to(device) \n",
    "\n",
    "for params in model.base_model.parameters(): \n",
    "    params.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"uitnlp/visobert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokens = tokenizer(df_train[\"words\"].to_list(), truncation=True, padding=True, return_tensors=\"pt\", is_split_into_words=True)\n",
    "test_tokens = tokenizer(df_test[\"words\"].to_list(), truncation=True, padding=True, return_tensors=\"pt\", is_split_into_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_tokens(tokens, df_type, label_all_tokens=True): \n",
    "    labels = [] \n",
    "    for i, label in enumerate(df_type[\"tokens\"]):\n",
    "        word_ids = tokens.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokens[\"labels\"] = labels\n",
    "    return tokens\n",
    "\n",
    "train_tokens = align_tokens(train_tokens, df_type=df_train)\n",
    "test_tokens = align_tokens(test_tokens, df_type=df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
