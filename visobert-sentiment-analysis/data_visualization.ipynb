{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from dataset import read_sentiment_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_sentiment_data(\"./data/sentiment/train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(data=df_train)\n",
    "df_train = df_train.convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  label                                              value\n",
      "0        0      1                          Cần tư vấn mà add  k rep\n",
      "\n",
      "1        1      1         Hotline khó gọi quá gọi mãi ko thưa máy à\n",
      "\n",
      "2        2      1  Mình thấy câu dịch vụ tốt nhất cho kh khó lắm....\n",
      "3        3      1  Em chọn chuyển tiền trong nước. Chuyển đến số ...\n",
      "4        4      1       Mình xài cái thể VISA của BIDV hạn mức 100tr\n",
      "...    ...    ...                                                ...\n",
      "1972  1972      2                                      Dạ em cảm ơn\n",
      "\n",
      "1973  1973      1  Có kinh nghiệm nhưng phải bằng đại học chính q...\n",
      "1974  1974      2                     Vietcombank tks add trước nha\n",
      "\n",
      "1975  1975      2                            Vietcombank ok tks add\n",
      "\n",
      "1976  1976      1                  Gọi k được mà tốn tiền như gì ấy\n",
      "\n",
      "\n",
      "[1977 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive label count: 1211\n",
      "negative label count: 743\n",
      "neutral label count: 23\n",
      "total: 1977 == 1977\n"
     ]
    }
   ],
   "source": [
    "positives = df_train['label'][df_train['label'] == 2].count()\n",
    "negatives = df_train['label'][df_train['label'] == 1].count()\n",
    "neutrals = df_train['label'][df_train['label'] == 0].count()\n",
    "\n",
    "print(f\"positive label count: {positives}\")\n",
    "print(f\"negative label count: {negatives}\")\n",
    "print(f\"neutral label count: {neutrals}\")\n",
    "\n",
    "print(f\"total: {positives + negatives + neutrals} == {df_train['label'].count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"5CD-AI/Vietnamese-Sentiment-visobert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"5CD-AI/Vietnamese-Sentiment-visobert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaTokenizerFast(name_or_path='5CD-AI/Vietnamese-Sentiment-visobert', vocab_size=15002, model_max_length=256, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t15001: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = tokenizer.vocab\n",
    "reversed_vocab = {v: k for k, v in vocab.items()} # reverse it so that we can retrieve the text from the token \n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cần tư vấn mà add  k rep\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[0].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tokenizer.encode(text=df_train.loc[0].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 0 -> <s>\n",
      "Token: 2615 -> ▁Cần\n",
      "Token: 749 -> ▁tư\n",
      "Token: 970 -> ▁vấn\n",
      "Token: 50 -> ▁mà\n",
      "Token: 2786 -> ▁add\n",
      "Token: 17 -> ▁k\n",
      "Token: 2321 -> ▁rep\n",
      "Token: 2 -> </s>\n"
     ]
    }
   ],
   "source": [
    "for id in t: \n",
    "    print(f\"Token: {id} -> {reversed_vocab[id]}\") # ignores new line character, a property of sentencepiece "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cần tư vấn mà add k rep\n"
     ]
    }
   ],
   "source": [
    "s = tokenizer.decode(t, skip_special_tokens=True) \n",
    "print(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
