{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dataset import read_sentiment_data\n",
    "import torch \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_2_LABEL = {\n",
    "    2: \"positive\", \n",
    "    1: \"negative\", \n",
    "    0: \"neutral\", \n",
    "}\n",
    "\n",
    "LABEL_2_ID = {\n",
    "     \"positive\": 2, \n",
    "     \"negative\": 1, \n",
    "     \"neutral\": 0 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_sentiment_data(\"./data/sentiment/train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(data=df_train)\n",
    "df_train = df_train.convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  label                                              value\n",
      "0        0      1                          Cần tư vấn mà add  k rep\n",
      "\n",
      "1        1      1         Hotline khó gọi quá gọi mãi ko thưa máy à\n",
      "\n",
      "2        2      1  Mình thấy câu dịch vụ tốt nhất cho kh khó lắm....\n",
      "3        3      1  Em chọn chuyển tiền trong nước. Chuyển đến số ...\n",
      "4        4      1       Mình xài cái thể VISA của BIDV hạn mức 100tr\n",
      "...    ...    ...                                                ...\n",
      "1972  1972      2                                      Dạ em cảm ơn\n",
      "\n",
      "1973  1973      1  Có kinh nghiệm nhưng phải bằng đại học chính q...\n",
      "1974  1974      2                     Vietcombank tks add trước nha\n",
      "\n",
      "1975  1975      2                            Vietcombank ok tks add\n",
      "\n",
      "1976  1976      1                  Gọi k được mà tốn tiền như gì ấy\n",
      "\n",
      "\n",
      "[1977 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive label count: 1211\n",
      "negative label count: 743\n",
      "neutral label count: 23\n",
      "total: 1977 == 1977\n"
     ]
    }
   ],
   "source": [
    "positives = df_train['label'][df_train['label'] == 2].count()\n",
    "negatives = df_train['label'][df_train['label'] == 1].count()\n",
    "neutrals = df_train['label'][df_train['label'] == 0].count()\n",
    "\n",
    "print(f\"positive label count: {positives}\")\n",
    "print(f\"negative label count: {negatives}\")\n",
    "print(f\"neutral label count: {neutrals}\")\n",
    "\n",
    "print(f\"total: {positives + negatives + neutrals} == {df_train['label'].count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"5CD-AI/Vietnamese-Sentiment-visobert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XLMRobertaForSequenceClassification(\n",
      "  (roberta): XLMRobertaModel(\n",
      "    (embeddings): XLMRobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(15004, 768, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): XLMRobertaEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x XLMRobertaLayer(\n",
      "          (attention): XLMRobertaAttention(\n",
      "            (self): XLMRobertaSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): XLMRobertaSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): XLMRobertaIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): XLMRobertaOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): XLMRobertaClassificationHead(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = model.to(\"cuda\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"5CD-AI/Vietnamese-Sentiment-visobert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaTokenizerFast(name_or_path='5CD-AI/Vietnamese-Sentiment-visobert', vocab_size=15002, model_max_length=256, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t15001: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = tokenizer.vocab\n",
    "reversed_vocab = {v: k for k, v in vocab.items()} # reverse it so that we can retrieve the text from the token \n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cần tư vấn mà add  k rep\\n'"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[0].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tokenizer.encode(text=df_train.loc[0].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 0 -> <s>\n",
      "Token: 2615 -> ▁Cần\n",
      "Token: 749 -> ▁tư\n",
      "Token: 970 -> ▁vấn\n",
      "Token: 50 -> ▁mà\n",
      "Token: 2786 -> ▁add\n",
      "Token: 17 -> ▁k\n",
      "Token: 2321 -> ▁rep\n",
      "Token: 2 -> </s>\n"
     ]
    }
   ],
   "source": [
    "for id in t: \n",
    "    print(f\"Token: {id} -> {reversed_vocab[id]}\") # ignores new line character, a property of sentencepiece "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cần tư vấn mà add k rep\n"
     ]
    }
   ],
   "source": [
    "s = tokenizer.decode(t, skip_special_tokens=True) \n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9])\n"
     ]
    }
   ],
   "source": [
    "input = df_train.loc[0]\n",
    "label = input.label \n",
    "input = tokenizer.encode(text=input.value) \n",
    "\n",
    "input = torch.tensor(input, dtype=torch.int32) \n",
    "input = input.reshape(1, -1)\n",
    "input = input.to(\"cuda\")\n",
    "print(input.shape) # (batch size, token length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 9, 768])\n"
     ]
    }
   ],
   "source": [
    "embedding = model.get_input_embeddings()\n",
    "embedding_vector = embedding(input)\n",
    "print(embedding_vector.shape) # (batch size, token length, embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=tensor(0.0540, device='cuda:0', grad_fn=<NllLossBackward0>), logits=tensor([[ 0.7181,  3.6212, -3.8046]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "output = model(input, labels=torch.tensor([1]).unsqueeze(0)) # the labels of the input) \n",
    "loss = output.loss\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1, device='cuda:0')\n",
      "Prediction label: negative\n",
      "Real label: negative\n"
     ]
    }
   ],
   "source": [
    "res = torch.argmax(output.logits) \n",
    "print(res)\n",
    "print(f\"Prediction label: {ID_2_LABEL[res.item()]}\")\n",
    "print(f\"Real label: {ID_2_LABEL[label]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input = df_train.loc[0].value\n",
    "# input= tokenizer(input, return_tensors=\"pt\", padding=True, truncation=True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
